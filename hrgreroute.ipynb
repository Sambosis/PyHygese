{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hygese in /usr/local/lib/python3.9/dist-packages (0.0.0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from hygese) (1.26.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hygese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1107483/2977106357.py:29: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import requests\n",
    "from folium import FeatureGroup\n",
    "\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "import math     \n",
    "import pandas as pd \n",
    "import pytest\n",
    "import matplotlib.pyplot as plt\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from scipy.spatial import ConvexHull\n",
    "from folium import Tooltip\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import collections\n",
    "import datetime\n",
    "import csv\n",
    "import math\n",
    "from geopy import Nominatim\n",
    "from IPython.core.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import datetime\n",
    "R = 6371.0\n",
    "EARTH_RADIUS = 6371.0\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "#calculate the average differnce between DAY AND NEW DAY\n",
    "def calculate_avg_diff(dataset):\n",
    "    avg_diff = 0\n",
    "    for i in range(len(dataset)):\n",
    "        avg_diff += abs(dataset['DAY'].iloc[i] - dataset['NEW DAY'].iloc[i])\n",
    "    avg_diff /= len(dataset)\n",
    "    return avg_diff\n",
    "\n",
    "\n",
    "# Step 1: Calculate the average 'DAY' for each 'NEW RT' and 'NEW DAY' combination\n",
    "\n",
    "def order_similar_to_prev(dataset):\n",
    "    # Step 1: Calculate the average 'DAY' for each 'NEW RT' and 'NEW DAY' combination\n",
    "    grouped_data = dataset.groupby(['NEW RT', 'NEW DAY'])['DAY'].mean().reset_index()\n",
    "    grouped_data = grouped_data.rename(columns={'DAY': 'AVERAGE_DAY'})\n",
    "\n",
    "    # Step 2: Sort these averages for each 'NEW RT' and reassign 'NEW DAY'\n",
    "    grouped_data.sort_values(['NEW RT', 'AVERAGE_DAY'], inplace=True)\n",
    "    grouped_data['NEW_DAY_SORTED'] = grouped_data.groupby('NEW RT').cumcount() + 1  # Start from 1\n",
    "\n",
    "    # Merge the sorted 'NEW DAY' back to the original dataset\n",
    "    dataset = dataset.merge(grouped_data[['NEW RT', 'NEW DAY', 'NEW_DAY_SORTED']], on=['NEW RT', 'NEW DAY'], how='left')\n",
    "    dataset['NEW DAY'] = dataset['NEW_DAY_SORTED']\n",
    "    dataset.drop('NEW_DAY_SORTED', axis=1, inplace=True)\n",
    "    return dataset\n",
    "    # Your 'NEW DAY' is now sorted based on the average 'DAY'\n",
    "def write_ouput_files(dataset):\n",
    "    # Import necessary libraries\n",
    "    import pandas as pd\n",
    "    import openpyxl\n",
    "    from tqdm import tqdm\n",
    "    from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "    # Function to auto-size columns\n",
    "    def autosize_columns(worksheet):\n",
    "        for column in worksheet.columns:\n",
    "            max_length = 0\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(cell.value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length -1)\n",
    "            worksheet.column_dimensions[cell.column_letter].width = adjusted_width\n",
    "        return worksheet\n",
    "\n",
    "    # Reload the original dataset\n",
    "    df = dataset\n",
    "\n",
    "    # Initialize a dictionary to hold the structured data for the route schedule\n",
    "    route_schedule = {}\n",
    "    # Populate the route_schedule dictionary based on the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        new_rt = row['NEW RT']\n",
    "        new_day = row['NEW DAY']\n",
    "        city = row['CITY']\n",
    "        cust_name = row['CUST NAME']\n",
    "        new_stop = row['NEW STOP']\n",
    "        machine = int(row['Machine'])\n",
    "        old_day = row['DAY']\n",
    "        comp = int(row['Companion'])\n",
    "        if new_rt not in route_schedule:\n",
    "            route_schedule[new_rt] = {}\n",
    "        \n",
    "        if new_day not in route_schedule[new_rt]:\n",
    "            route_schedule[new_rt][new_day] = {'cities': set(), 'customers': []}\n",
    "        \n",
    "        route_schedule[new_rt][new_day]['cities'].add(city)\n",
    "        route_schedule[new_rt][new_day]['customers'].append({'name': cust_name, 'stop': new_stop, 'machine': machine, 'DAY': old_day, 'NEW DAY': new_day, 'Companion': comp})\n",
    "    # Check the structure by showing data for one route\n",
    "    next(iter(route_schedule.items()))\n",
    "    # Initialize a new Excel workbook and remove the default sheet\n",
    "    wb = openpyxl.Workbook()\n",
    "    default_sheet = wb.active\n",
    "    wb.remove(default_sheet)\n",
    "\n",
    "    # Function to fill in the customer details for each day and stop\n",
    "    # This code fills the customer details for each day, stop, route combination.\n",
    "    # It uses the route_data dictionary to find the customer details for each stop on each day.\n",
    "    # If there is no data in the route_data dictionary for a given day, stop, route combination,\n",
    "    # then it leaves the cell blank.\n",
    "\n",
    "    def fill_customer_details(sheet, row, col, day, stop, route_data):\n",
    "        data = route_data.get(day, {}).get('customers', [])\n",
    "\n",
    "        for customer in data:\n",
    "            if customer['stop'] == stop:\n",
    "                sheet.cell(row=row, column=col, value=stop)\n",
    "                sheet.cell(row=row, column=col+1, value=customer['name'].title())\n",
    "                sheet.cell(row=row, column=col+2, value=f\"${customer['machine']}/ ${customer['Companion']}\")\n",
    "                return\n",
    "        sheet.cell(row=row, column=col, value=\"\")\n",
    "        sheet.cell(row=row, column=col+1, value=\"\")\n",
    "        sheet.cell(row=row, column=col+2, value=\"\")\n",
    "\n",
    " \n",
    "    # Font and Fill styles\n",
    "    bold_font = Font(bold=True)\n",
    "    italic_font = Font(italic=True)\n",
    "    blue_fill = PatternFill(start_color=\"00CCFF\", end_color=\"00CCFF\", fill_type=\"solid\")\n",
    "\n",
    "\n",
    "    # Loop through each unique NEW RT\n",
    "    for route in route_schedule.keys():\n",
    "        ws = wb.create_sheet(title=str(route))\n",
    "        ws.page_setup.orientation = ws.ORIENTATION_LANDSCAPE  # Set page to landscape\n",
    "\n",
    "        # Initialize row and column pointers\n",
    "        row = 1\n",
    "        col = 1  \n",
    "        # Initialize day counter for column headers\n",
    "        day_counter = 1\n",
    "        while day_counter <= 20:  # There will never be more than 25 days\n",
    "            # Fill in the column headers for the days and customer details\n",
    "            cell = ws.cell(row=row, column=col+1, value=f\"Day {day_counter}\")\n",
    "            cell.font = bold_font  # Make it bold\n",
    "            # Update header names and styles\n",
    "            ws.cell(row=row+1, column=col, value=\"Stop\").font = italic_font\n",
    "            ws.cell(row=row+1, column=col+1, value=\"Customer\").font = italic_font\n",
    "            ws.cell(row=row+1, column=col+2, value=\"Sales/Comp\").font = italic_font  # Changed from \"Machine\" to \"Sales\"\n",
    "            # Apply light blue background to headers\n",
    "            for c in range(col, col+3):\n",
    "                ws.cell(row=row+1, column=c).fill = blue_fill\n",
    "\n",
    "            # Fill in customer details for each stop (1-10)\n",
    "            for stop in range(1, 9):  # There will never be more than 10 stops\n",
    "                fill_customer_details(ws, row=row+1+stop, col=col, day=day_counter, stop=stop, route_data=route_schedule[route])\n",
    "            \n",
    "            # Update the column pointer to skip to the next day block (3 columns per day, removed empty column)\n",
    "            col += 3\n",
    "            day_counter += 1\n",
    "            \n",
    "            # Check if we've filled in 5 days, if so, skip a row and reset column pointer\n",
    "            if (day_counter - 1) % 5 == 0:\n",
    "                row += 11  # Skip to next block of rows (10 stops + 2 header rows + 1 empty row)\n",
    "                col = 1  # Reset to column B\n",
    "    \n",
    "        autosize_columns(ws)\n",
    "    #create workbook file name that includes the date and time\n",
    "    now = datetime.datetime.now()\n",
    "    date_time_str = now.strftime(\"%m%d%Y_%H%M%S\")\n",
    "\n",
    "    # Save the Excel workbook\n",
    "    wb.save(f'./data/Route_Schedule_Formatted_{date_time_str}.xlsx')\n",
    "    #save dataset to a csv file for future use\n",
    "    dataset.to_csv(f'./data/reroute_dataset_{date_time_str}.csv')\n",
    "def print_starts_ends(data,dataset):\n",
    "    for start in data['starts']:\n",
    "        crint(dataset.iloc[start]['CUST NAME'],\"white\", \"dark grey\", \"italic\")\n",
    "    for endd in data['ends']:\n",
    "        crint(dataset.iloc[endd]['CUST NAME'],\"white\", \"dark grey\", \"italic\")\n",
    "def best_tracker(solution, prev_obj, best_obj):\n",
    "    crint(f\"\"\"The current solution was completed in {solution.ObjectiveValue()} km. \"\"\",\"white\", \"dark grey\", \"bold_italic\")\n",
    "    crint(f\"\"\"The previous best solution was completed in {best_obj} km.\"\"\",\"white\", \"dark grey\", \"bold_italic\")\n",
    "    crint(f\"The most previous solution was completed in {prev_obj} km.\",\"white\", \"dark grey\", \"bold_italic\")\n",
    "    if best_obj > solution.ObjectiveValue():\n",
    "        best_obj = solution.ObjectiveValue()\n",
    "        crint(f\"Therefore, we have a new best solution with a value of {str(best_obj)} km\", \"red\", \"yellow\", \"bold_italic\")\n",
    "    else:    \n",
    "        if prev_obj > solution.ObjectiveValue():\n",
    "            crint(f\"Therefore, we have solution that is better than the previous by {prev_obj - solution.ObjectiveValue()} km\",\"white\", \"dark grey\", \"bold_italic\")\n",
    "        else:\n",
    "            crint(f\"Therefore, the current solution is  {solution.ObjectiveValue()-prev_obj} km longer\",\"white\", \"dark grey\", \"bold_italic\")\n",
    "    prev_obj = solution.ObjectiveValue()\n",
    "    return prev_obj, best_obj\n",
    "def get_new_stop_count(dataset):\n",
    "    # Get the number of stops from each route\n",
    "    stop_count = dataset.groupby('Vehicle')['NEW DAY'].nunique()\n",
    "    return stop_count\n",
    "import networkx as nx\n",
    "from haversine import haversine, Unit\n",
    "from os import write\n",
    "# Define a function to calculate the distance between two nodes\n",
    "def calculate_distance(node1, node2):\n",
    "    lat1, lon1 = node1['Latitude'], node1['Longitude']\n",
    "    lat2, lon2 = node2['Latitude'], node2['Longitude']\n",
    "    return haversine((lat1, lon1), (lat2, lon2))\n",
    "def split_into_days(path, graph, min_stops, max_stops):\n",
    "    days = []\n",
    "    while len(path) > min_stops:\n",
    "        max_distance = 0\n",
    "        split_point = min(max_stops, len(path))\n",
    "        for i in range(min_stops, min(max_stops, len(path) - 1)):  # ensure we don't go out of range\n",
    "            distance = graph[path[i]][path[i+1]]['weight']\n",
    "            if distance > max_distance:\n",
    "                max_distance = distance\n",
    "                split_point = i + 1\n",
    "        days.append(path[:split_point])\n",
    "        path = path[split_point:]\n",
    "    if path:\n",
    "        days.append(path)\n",
    "    return days\n",
    "def set_days_for_each_route(dataset, min_stops=5, max_stops=8):\n",
    "    unique_routes = dataset['Vehicle'].unique()\n",
    "\n",
    "    branch = 650\n",
    "    # Iterate over unique routes\n",
    "    for route in unique_routes:\n",
    "        # Subset your data for the current route\n",
    "        subset_data = dataset[dataset['Vehicle'] == route]\n",
    "        # Create a graph for this route\n",
    "        graph = nx.Graph()\n",
    "        # Add nodes to the graph\n",
    "        for index, row in subset_data.iterrows():\n",
    "            graph.add_node(index, Latitude=row['Latitude'], Longitude=row['Longitude'])\n",
    "        # Add edges to the graph (complete graph, every node is connected to every other node)\n",
    "        for node1, data1 in graph.nodes(data=True):\n",
    "            for node2, data2 in graph.nodes(data=True):\n",
    "                if node1 != node2:\n",
    "                    distance = calculate_distance(data1, data2)\n",
    "                    graph.add_edge(node1, node2, weight=distance)\n",
    "\n",
    "        \n",
    "        # Find the shortest path in the graph\n",
    "        # Note: This assumes that the depot is the first node in the subset_data DataFrame\n",
    "        depot = subset_data.index[0]\n",
    "        path = nx.approximation.christofides(graph)#, source=depot)\n",
    "\n",
    "        # Split the path into days\n",
    "        days = split_into_days(path, graph,min_stops, max_stops)\n",
    "        # Assign the order of the path and the day to the 'DAY' and 'DAY_ORDER' columns of the subset_data DataFrame\n",
    "        day_order = 0\n",
    "    \n",
    "        # print(f\"Route {1+route}: \\n\")\n",
    "        with open('prtout.txt', 'a') as f:\n",
    "            f.write(f\"Route {1+route}: \\n\")\n",
    "        for day, stops in enumerate(days, start=1):\n",
    "            day_order = 1\n",
    "            #print(f\"\\n Route: {1+route} Day: {day} \\n\")\n",
    "            for stop in stops:            \n",
    "                dataset.loc[stop, 'NEW BR'] = branch\n",
    "                dataset.loc[stop, 'NEW RT'] = route +1\n",
    "                dataset.loc[stop, 'NEW DAY'] = day\n",
    "                #subset_data.loc[stop, 'DAY ORDER'] = day_order\n",
    "                dataset.loc[stop, 'DAY ORDER'] = day_order\n",
    "                dataset.loc[stop, 'NEW STOP'] = day_order\n",
    "\n",
    "                dataset.loc[dataset['CUST'] == subset_data.loc[stop, 'CUST'], 'DAY ORDER'] = day_order\n",
    "                subset_data = dataset[dataset['Vehicle'] == route].copy()\n",
    "\n",
    "                \n",
    "                with open('prtout.txt', 'a') as f:\n",
    "                    f.write(f\"\"\"{day_order}: {subset_data.loc[stop, 'CUST NAME']} Sales: ${int(subset_data.loc[stop, 'Machine'])} Companion: ${int(subset_data.loc[stop, 'Companion'])} \\n   {subset_data.loc[stop, 'ADDRESS']} \"\"\")\n",
    "                day_order += 1\n",
    "\n",
    "        # Update the original dataset with the new 'DAY' and 'DAY_ORDER' values for the current route\n",
    "        dataset.update(subset_data)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    dataset.to_csv('your_updated_dataset.csv')\n",
    "    return dataset\n",
    "# Define a function to calculate the distance between two nodes\n",
    "\n",
    "def set_path_for_each_route(dataset):\n",
    "    # Get unique routes\n",
    "    unique_routes = dataset['Vehicle'].unique()\n",
    "    # Iterate over unique routes\n",
    "    for route in unique_routes:\n",
    "        # Subset your data for the current route\n",
    "        subset_data = dataset[dataset['Vehicle'] == route]\n",
    "        # Create a graph for this route\n",
    "        graph = nx.Graph()\n",
    "        # Add nodes to the graph\n",
    "        for index, row in subset_data.iterrows():\n",
    "            graph.add_node(index, Latitude=row['Latitude'], Longitude=row['Longitude'])\n",
    "        # Add edges to the graph (complete graph, every node is connected to every other node)\n",
    "        for node1, data1 in graph.nodes(data=True):\n",
    "            for node2, data2 in graph.nodes(data=True):\n",
    "                if node1 != node2:\n",
    "                    distance = calculate_distance(data1, data2)\n",
    "                    graph.add_edge(node1, node2, weight=distance)\n",
    "        # Find the shortest path in the graph\n",
    "        # Note: This assumes that the depot is the first node in the subset_data DataFrame\n",
    "        depot = subset_data.index[0]\n",
    "        path = nx.approximation.greedy_tsp(graph)#, source=depot)\n",
    "        # Assign the order of the path to the 'DAY' column of the subset_data DataFrame\n",
    "        for order, node in enumerate(path):\n",
    "            subset_data.loc[node, 'DAY ORDER'] = order\n",
    "        # Update the original dataset with the new 'DAY' values for the current route\n",
    "        dataset.update(subset_data)\n",
    "    dataset['ROUTE'] = dataset['Vehicle']\n",
    "    # Save the updated dataset\n",
    "    dataset.to_csv('your_updated_dataset.csv')\n",
    "    return dataset\n",
    "def haversinedm(lat1: float, lon1: float, lat2: float, lon2: float, unit: str = 'kilometers') -> float:\n",
    "    \"\"\"\n",
    "    Calculate the distance between two points on the Earth's surface using the Haversine formula.\n",
    "\n",
    "    Parameters:\n",
    "        lat1 (float): Latitude of the first point in degrees.\n",
    "        lon1 (float): Longitude of the first point in degrees.\n",
    "        lat2 (float): Latitude of the second point in degrees.\n",
    "        lon2 (float): Longitude of the second point in degrees.\n",
    "        unit (str): Unit of the distance result. Default is 'kilometers'.\n",
    "\n",
    "    Returns:\n",
    "        distance (float): The distance between the two points in the specified unit.\n",
    "    \"\"\"\n",
    "    # Check if the latitude and longitude values are within valid ranges\n",
    "    if not (-90 <= lat1 <= 90) or not (-90 <= lat2 <= 90) or not (-180 <= lon1 <= 180) or not (-180 <= lon2 <= 180):\n",
    "        raise ValueError(\"Invalid latitude or longitude values\")\n",
    "\n",
    "    # Convert the latitude and longitude values from degrees to radians\n",
    "    lat1_rad = np.radians(lat1)\n",
    "    lon1_rad = np.radians(lon1)\n",
    "    lat2_rad = np.radians(lat2)\n",
    "    lon2_rad = np.radians(lon2)\n",
    "\n",
    "    # Calculate the differences in latitude and longitude in radians\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Define helper functions to calculate the intermediate values 'a' and 'c' in the Haversine formula\n",
    "    def calculate_a(dlat: float, dlon: float) -> float:\n",
    "        return np.sin(dlat / 2) ** 2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2) ** 2\n",
    "\n",
    "    def calculate_c(a: float) -> float:\n",
    "        return 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    # Calculate the intermediate values 'a' and 'c' using the helper functions\n",
    "    a = calculate_a(dlat, dlon)\n",
    "    c = calculate_c(a)\n",
    "\n",
    "    # Calculate the distance using the Haversine formula and the Earth's radius 'R'\n",
    "    distance = EARTH_RADIUS * c\n",
    "\n",
    "    # Check if the unit is valid\n",
    "    conversion_factors = {\n",
    "        'miles': 0.621371,\n",
    "        'kilometers': 1,\n",
    "        'nautical miles': 0.539957,\n",
    "    }\n",
    "    if unit not in conversion_factors:\n",
    "        raise ValueError(\"Invalid unit\")\n",
    "\n",
    "    # Convert the distance using the appropriate conversion factor based on the unit\n",
    "    distance *= conversion_factors[unit]\n",
    "\n",
    "    return distance\n",
    "def calculate_a(dlat, lat1_in_radians, lat2_in_radians, dlon):\n",
    "    return math.sin(dlat / 2)**2 + math.cos(lat1_in_radians) * math.cos(lat2_in_radians) * math.sin(dlon / 2)**2\n",
    "def calculate_c(a):\n",
    "    return 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "def print_solution(data, manager, routing, solution, dataset):\n",
    "    total_distance = 0  # Total distance covered by all the vehicles\n",
    "    total_load = 0  # Total load carried by all the vehicles\n",
    "    total_load2 = 0  # Total load carried by all the vehicles\n",
    "    previous_index = routing.Start(0)\n",
    "    for vehicle_id in range(data['num_vehicles']):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        plan_output = 'Route  {}:\\n'.format(vehicle_id)\n",
    "        route_distance = 0  # Distance covered by the current vehicle\n",
    "        route_load = 0  # Load carried by the current vehicle\n",
    "        route_load2 = 0  # Load carried by the current vehicle\n",
    "        route_count = 0  # Count of stops made by the current vehicle\n",
    "        while not routing.IsEnd(index):\n",
    "            plan_output += ' {} -> '.format(manager.IndexToNode(index))\n",
    "            #add the index row of dataset to plan_output\n",
    "            plan_output += ' {} -> '.format(dataset.iloc[index]['CUST NAME'])\n",
    "            plan_output += ' {}m\\n'.format(routing.GetArcCostForVehicle(previous_index, index, vehicle_id))\n",
    "            route_count += 1\n",
    "            node_index = manager.IndexToNode(index)  #\n",
    "            route_load += data['demands'][node_index]\n",
    "            route_load2 += data['demands2'][node_index]\n",
    "            data['Vehicle'][node_index] = vehicle_id\n",
    "            \n",
    "            previous_index = index\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "            route_distance += routing.GetArcCostForVehicle(previous_index, index, vehicle_id)\n",
    "        route_load += data['demands'][node_index]\n",
    "        route_load2 += data['demands2'][node_index]\n",
    "        data['Vehicle'][node_index] = vehicle_id\n",
    "        \n",
    "        crint('Route {} has {} stops ({})\\n'.format(vehicle_id+1, route_count, data['vehicle_capacities3'][vehicle_id]),forecolor=\"cyan\",backcolor=\"navy\",style=\"bold_italic\",font_size=20)\n",
    "        crint('Companion: ${:,.0f} ({}) \\n'.format(route_load, data['vehicle_capacities'][vehicle_id]), indent=30,style=\"bold_italic\")\n",
    "        crint('Big 5: ${:,.0f} ({})\\n'.format(route_load2, data['vehicle_capacities2'][vehicle_id]), indent=30,style=\"bold_italic\")\n",
    "        crint('Distance: {}m\\n'.format(route_distance), indent=30,style=\"bold_italic\",font_size=18)\n",
    "        total_distance += route_distance\n",
    "        total_load += route_load  # Add the load carried by the vehicle to the total load\n",
    "        total_load2 += route_load2  # Add the load carried by the vehicle to the total load\n",
    "    crint('Total Distance of all routes: {}m'.format(total_distance),forecolor=\"cyan\",backcolor=\"navy\",style=\"bold_italic\",font_size=20)\n",
    "    # SET dataset['NEW RT'] TO THE VALUE OF DATA['VEHICLE'] + 1 FOR ALL ROWS\n",
    "    # Ensure data['Vehicle'] is a pandas Series or compatible with the dataset index\n",
    "    dataset['NEW RT'] = pd.Series(data['Vehicle']) + 1\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def create_map(data, dataset):\n",
    "    \"\"\"\n",
    "    Generates a map with markers and polygons to visualize data points and clusters.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary containing the 'Vehicle' key with a list of vehicle IDs.\n",
    "        dataset (DataFrame): A pandas DataFrame containing the latitude, longitude, companion, and machine data for each data point.\n",
    "\n",
    "    Returns:\n",
    "        m (folium.Map): The generated map with markers and polygons representing the data points and clusters.\n",
    "    \"\"\"\n",
    "    dataset_cp = dataset.copy()\n",
    "    dataset_cp = dataset_cp[['Latitude', 'Longitude', 'Companion', 'Machine']]\n",
    "    # add a column to dataset_cp that has vehicle from data['Vehicle']\n",
    "    dataset_cp['Vehicle'] = data['Vehicle']\n",
    "    companion_total = dataset_cp.groupby('Vehicle')['Companion'].sum()\n",
    "    machine_total = dataset_cp.groupby('Vehicle')['Machine'].sum()\n",
    "    # Calculate the size of each cluster\n",
    "    cluster_sizes = dataset_cp.groupby('Vehicle').size()\n",
    "    #centers_df = pd.merge(centers_df, cluster_sizes.rename('Size'), left_on='Cluster', right_index=True)\n",
    "    # centers_df['Size'] = centers_df['Cluster'].apply(lambda x: len(cust_numb_dict[x]))\n",
    "    m = folium.Map(tiles='https://api.mapbox.com/styles/v1/mapbox/satellite-streets-v12/tiles/256/{z}/{x}/{y}?access_token=pk.eyJ1Ijoic2FtYm9zaXMiLCJhIjoiY2xyenJyM2h5MWlvMDJpcGV3NnJ3MTdkeSJ9.AGWk1gj--GW99AM0IbF3rg', attr='Mapbox', location=[dataset['Latitude'].mean(), dataset['Longitude'].mean()], zoom_start=9, max_zoom=20)\n",
    "    # attr='Mapbox',\n",
    "    # name='Mapbox Satellite',\n",
    "    # overlay=True,\n",
    "    # control=True\n",
    "    # Generate a color map for each unique vehicle\n",
    "    vehicle_ids = dataset_cp['Vehicle'].unique()\n",
    "    colors = [f\"#{''.join([np.random.choice(list('ABCDEF0123456789')) for j in range(6)])}\" for i in range(\n",
    "        len(vehicle_ids))]\n",
    "    color_map = dict(zip(vehicle_ids, colors))\n",
    "    for vehicle in vehicle_ids:\n",
    "        # Extract the data for this vehicle\n",
    "        vehicle_data = dataset_cp[dataset_cp['Vehicle'] == vehicle][['Latitude', 'Longitude']].values\n",
    "\n",
    "        # Calculate the Convex Hull of the vehicle points\n",
    "        if len(vehicle_data) > 2:  # ConvexHull requires at least 3 points\n",
    "            hull = ConvexHull(vehicle_data)\n",
    "            # Draw the Convex Hull as a polygon on the map\n",
    "            folium.Polygon(locations=vehicle_data[hull.vertices].tolist(),\n",
    "                        fill=True,\n",
    "                        color=color_map[vehicle],\n",
    "                        tooltip=Tooltip(f\"Route: {vehicle+1}, Stop Count: {cluster_sizes[vehicle]}, Total Companion: {companion_total[vehicle]}, Big 5: {machine_total[vehicle]}\")).add_to(m)\n",
    "        # Draw the markers for the vehicle\n",
    "        FastMarkerCluster(vehicle_data.tolist()).add_to(m)\n",
    " \n",
    "\n",
    "    # Save and render the map\n",
    "    m.save('map.html')\n",
    "    m.render()\n",
    "    # Display the map\n",
    "    return m\n",
    "import folium\n",
    "from matplotlib import colors as mcolors\n",
    "from folium import plugins\n",
    "from folium.features import DivIcon\n",
    "def get_good_map(dataset):\n",
    "    dataset = dataset.sort_values(['NEW RT', 'NEW DAY'])\n",
    "    vehicles = dataset['NEW RT'].unique()\n",
    "    # Create a Map instance\n",
    "    m = folium.Map(tiles='https://api.mapbox.com/styles/v1/mapbox/satellite-streets-v12/tiles/256/{z}/{x}/{y}@2x?access_token=pk.eyJ1Ijoic2FtYm9zaXMiLCJhIjoiY2xyenJyM2h5MWlvMDJpcGV3NnJ3MTdkeSJ9.AGWk1gj--GW99AM0IbF3rg', attr='Mapbox', location=[39.7, -76.5], zoom_start=9, max_zoom=20)\n",
    "    # Create a color map\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())  # list of named colors\n",
    "    color_map = {vehicle: colors[i+13] for i, vehicle in enumerate(vehicles)}\n",
    "\n",
    "    # Create a layer for each route\n",
    "    for vehicle in dataset['NEW RT'].unique():\n",
    "        route = folium.FeatureGroup(name=f'Route {vehicle}')\n",
    "        vehicle_data = dataset[dataset['NEW RT'] == vehicle]\n",
    "        # Add points to the route\n",
    "        for index, row in vehicle_data.iterrows():\n",
    "            tooltip_text = f\"\"\"\n",
    "            <table style=\"width:100%\">\n",
    "                <tr>\n",
    "                <th>Name:</th>\n",
    "                <td><a href=\"https://www.google.com/search?q={row['CUST NAME']}+{row['ADDRESS']}\" target=\"_blank\">{row['CUST NAME']}</a></td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                <th>Index:</th>\n",
    "                <td>{index}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                <th>Index:</th>\n",
    "                <td>{index}</td>\n",
    "                </tr>       \n",
    "                <tr>\n",
    "                <th>Address:</th>\n",
    "                <td><a href=\"https://www.google.com/maps/dir//{row['ADDRESS']}\" target=\"_blank\">{row['ADDRESS']}</a></td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                <th>Companion:</th>\n",
    "                <td>${row['Companion']:,.2f}</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                <th>Sales:</th>\n",
    "                <td>${row['Machine']:,.2f}0</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                <th>Day:</th>\n",
    "                <td>{int(row['NEW DAY'])}</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "            \"\"\"\n",
    "            iframe = folium.IFrame(html=tooltip_text, width=400, height=150)\n",
    "            folium.CircleMarker(\n",
    "                location=[row['Latitude'], row['Longitude']],\n",
    "                popup=tooltip_text,\n",
    "                tooltip=tooltip_text,\n",
    "                color='#3186cc',\n",
    "                fill=True,\n",
    "                fill_color='#3186cc',\n",
    "                radius = 12,\n",
    "                weight = 5\n",
    "            ).add_to(route)\n",
    "        # Add lines to the route\n",
    "        locations = vehicle_data[['Latitude', 'Longitude']].values.tolist()\n",
    "        folium.Polygon(locations=locations, color=color_map[vehicle], fill=True, fill_opacity=0.3, weight=2).add_to(route)\n",
    "        # Add the route to the map\n",
    "        route.add_to(m)\n",
    "    plugins.Fullscreen(\n",
    "    position=\"topleft\",\n",
    "    title=\"Expand me\",\n",
    "    title_cancel=\"Exit me\",\n",
    "    force_separate_button=True,\n",
    "    ).add_to(m)\n",
    "    # Add a layer control to the map\n",
    "    folium.LayerControl().add_to(m)\n",
    "    m.save(\"goodmap.html\")\n",
    "    return m\n",
    "def crint(string_to_print, forecolor='black', backcolor='white', style='normal', indent=0, font_size=17):\n",
    "    \"\"\"\n",
    "    Custom print function to display colored text in a Jupyter Notebook using HTML.\n",
    "    Parameters:\n",
    "        string_to_print (str): The string to print.\n",
    "        forecolor (str): The text color.\n",
    "        backcolor (str): The background color.\n",
    "        style (str): The text style ('normal', 'bold', 'italic').\n",
    "        indent (int): The left margin indentation in pixels.\n",
    "    \"\"\"\n",
    "    style_mapping = {\n",
    "        'normal': 'font-style: normal; font-weight: normal; text-decoration: none;',\n",
    "        'bold': 'font-style: normal; font-weight: bold; text-decoration: none;',\n",
    "        'italic': 'font-style: italic; font-weight: normal; text-decoration: none;',\n",
    "        'bold_italic': 'font-style: italic; font-weight: bold; text-decoration: none;',\n",
    "        'underline': 'font-style: normal; font-weight: normal; text-decoration: underline;',\n",
    "        'strikethrough': 'font-style: normal; font-weight: normal; text-decoration: line-through;',\n",
    "        'overline': 'font-style: normal; font-weight: normal; text-decoration: overline;'\n",
    "    }\n",
    "\n",
    "    \n",
    "    css_style = f\"color: {forecolor}; background-color: {backcolor}; {style_mapping.get(style, 'font-style: normal; font-weight: normal; text-decoration: none;')} margin-left: {indent}px; font-size: {font_size}px\"\n",
    "    display(HTML(f\"<span style='{css_style}'>{string_to_print}</span>\"))\n",
    "#imports to perform a wait\n",
    "import time \n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "def print_days_per_route(dataset, data):\n",
    "    i = 0\n",
    "    for cunt in dataset.groupby('NEW RT')['NEW DAY'].nunique():\n",
    "        i += 1\n",
    "        crint(f\"Route {i} Days: {cunt} ({data['demands3'][i]})\",'cyan', 'navy')\n",
    "def write_solution(dataset):\n",
    "    now = datetime.datetime.now()\n",
    "    with open(f'routewithdays {now.day}-{now.month}-{now.year} {now.hour}{now.minute}.csv','a') as ff:\n",
    "        writer = csv.writer(ff)\n",
    "        writer.writerow([\"Route\", \"Route Day\", \"Stop\", \"Name\", \"Address\", \"Big 5\", \"Companion\", \"Distance\"])\n",
    "        for vehicle_id in dataset['Vehicle'].unique():\n",
    "            c_stop = 0\n",
    "            # Loop through all rows in dataset where dataset['Vehicle'] == vehicle_id\n",
    "            subset_data = dataset[dataset['Vehicle'] == vehicle_id]\n",
    "            for index, row in subset_data.iterrows():\n",
    "                c_route = vehicle_id + 1\n",
    "                c_stop += 1\n",
    "                c_name = row['CUST NAME']\n",
    "                c_addy = row['ADDRESS']\n",
    "                c_big = row['Machine']\n",
    "                c_comp = row['Companion']\n",
    "                c_route_day = row['DAY']\n",
    "                writer.writerow([c_route, c_route_day, c_stop, c_name, c_addy, c_big, c_comp])\n",
    "\n",
    "def create_clean_map(data, dataset):\n",
    "    \"\"\"\n",
    "    Generates a map with markers and polygons to visualize data points and clusters in a cleaner, more efficient way.\n",
    "\n",
    "    Args:\n",
    "        data (dict): A dictionary containing the 'Vehicle' key with a list of vehicle IDs.\n",
    "        dataset (DataFrame): A DataFrame containing latitude, longitude, companion, and machine data for each data point.\n",
    "\n",
    "    Returns:\n",
    "        folium.Map: The generated map with markers and polygons representing the data points and clusters.\n",
    "    \"\"\"\n",
    "    # Ensure 'Vehicle' data is in a format that can be used to create a new column in dataset\n",
    "    if 'Vehicle' in data:\n",
    "        dataset['Vehicle'] = pd.Categorical(dataset.index.map(lambda x: data['Vehicle'][x % len(data['Vehicle'])]))\n",
    "    else:\n",
    "        raise ValueError(\"Data must contain 'Vehicle' key with a list of vehicle IDs.\")\n",
    "    \n",
    "    # Subset the dataset to relevant columns\n",
    "    relevant_columns = ['Latitude', 'Longitude', 'Companion', 'Machine', 'Vehicle']\n",
    "    dataset = dataset[relevant_columns].dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "    # Aggregate data\n",
    "    companion_total = dataset.groupby('Vehicle')['Companion'].sum()\n",
    "    machine_total = dataset.groupby('Vehicle')['Machine'].sum()\n",
    "    cluster_sizes = dataset.groupby('Vehicle').size()\n",
    "\n",
    "    # Initialize map\n",
    "    map_center = [dataset['Latitude'].mean(), dataset['Longitude'].mean()]\n",
    "    m = folium.Map(location=map_center, zoom_start=9, max_zoom=20, tiles='https://api.mapbox.com/styles/v1/mapbox/satellite-streets-v12/tiles/256/{z}/{x}/{y}?access_token=pk.eyJ1Ijoic2FtYm9zaXMiLCJhIjoiY2xyenJyM2h5MWlvMDJpcGV3NnJ3MTdkeSJ9.AGWk1gj--GW99AM0IbF3rg', attr='Mapbox')\n",
    "\n",
    "    # Generate color map\n",
    "    vehicle_ids = dataset['Vehicle'].unique()\n",
    "    colors = [f\"#{''.join(np.random.choice(list('ABCDEF0123456789'), 6))}\" for _ in vehicle_ids]\n",
    "    color_map = dict(zip(vehicle_ids, colors))\n",
    "\n",
    "    for vehicle in vehicle_ids:\n",
    "        vehicle_data = dataset[dataset['Vehicle'] == vehicle][['Latitude', 'Longitude']]\n",
    "        if len(vehicle_data) > 2:\n",
    "            points = vehicle_data.values\n",
    "            try:\n",
    "                hull = ConvexHull(points)\n",
    "                folium.Polygon(locations=points[hull.vertices].tolist(), fill=True, color=color_map[vehicle], tooltip=Tooltip(f\"Vehicle: {vehicle}, Stop Count: {cluster_sizes[vehicle]}, Total Companion: {companion_total[vehicle]}, Total Machine: {machine_total[vehicle]}\")).add_to(m)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not create a convex hull for vehicle {vehicle}: {e}\")\n",
    "        FastMarkerCluster(data=vehicle_data.values.tolist()).add_to(m)\n",
    "\n",
    "    return m\n",
    "\n",
    "# Example usage (assuming 'data' and 'dataset' are predefined and properly formatted)\n",
    "# m = create_clean_map(data, dataset)\n",
    "# m.save('clean_map.html')\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def create_clean_map_from_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Generates a map with markers and polygons to visualize routes based on the 'NEW RT' column in the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): A pandas DataFrame containing latitude, longitude, and other data for each point.\n",
    "\n",
    "    Returns:\n",
    "        folium.Map: The generated map with markers and polygons representing the routes.\n",
    "    \"\"\"\n",
    "    # Ensure dataset is sorted by 'NEW RT' and 'NEW DAY' for coherent route tracing\n",
    "    dataset = dataset.sort_values(['NEW RT', 'NEW DAY'])\n",
    "    \n",
    "    # Initialize map\n",
    "    m = folium.Map(\n",
    "        location=[39.7, -76.5],\n",
    "        zoom_start=9,\n",
    "        max_zoom=20,\n",
    "        tiles='https://api.mapbox.com/styles/v1/mapbox/satellite-streets-v12/tiles/256/{z}/{x}/{y}@2x?access_token=pk.eyJ1Ijoic2FtYm9zaXMiLCJhIjoiY2xyenJyM2h5MWlvMDJpcGV3NnJ3MTdkeSJ9.AGWk1gj--GW99AM0IbF3rg',\n",
    "        attr='Mapbox'\n",
    "    )\n",
    "    \n",
    "    # Generate color map for routes\n",
    "    vehicles = dataset['NEW RT'].unique()\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())[13:13+len(vehicles)]  # Adjust if more vehicles than colors\n",
    "    color_map = dict(zip(vehicles, colors))\n",
    "    \n",
    "    for vehicle in vehicles:\n",
    "        route = folium.FeatureGroup(name=f'Route {vehicle}')\n",
    "        vehicle_data = dataset[dataset['NEW RT'] == vehicle]\n",
    "        \n",
    "        # Add points and lines for each route\n",
    "        for index, row in vehicle_data.iterrows():\n",
    "            # Tooltip and popup text\n",
    "            tooltip_text = f\"Route: {vehicle}, Day: {row['NEW DAY']}, Sales: ${row['Machine']:,.2f}\"\n",
    "            folium.CircleMarker(\n",
    "                location=[row['Latitude'], row['Longitude']],\n",
    "                tooltip=tooltip_text,\n",
    "                color=color_map[vehicle],\n",
    "                fill=True,\n",
    "                fill_color=color_map[vehicle],\n",
    "                radius=5\n",
    "            ).add_to(route)\n",
    "        \n",
    "        # Add route lines\n",
    "        locations = vehicle_data[['Latitude', 'Longitude']].values.tolist()\n",
    "        if len(locations) > 1:  # Only draw lines if more than one location\n",
    "            folium.PolyLine(locations=locations, color=color_map[vehicle], weight=2.5, opacity=0.8).add_to(route)\n",
    "        \n",
    "        route.add_to(m)\n",
    "    \n",
    "    # Add fullscreen button\n",
    "    Fullscreen().add_to(m)\n",
    "    \n",
    "    # Add LayerControl\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    # Save the map\n",
    "    m.save(\"clean_map.html\")\n",
    "    return m\n",
    "\n",
    "def create_map_with_convex_hull(dataset):\n",
    "    \"\"\"\n",
    "    Generates a map with markers, lines, and convex hull polygons to visualize routes based on the 'NEW RT' column.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): A pandas DataFrame containing latitude, longitude, and other data for each point.\n",
    "\n",
    "    Returns:\n",
    "        folium.Map: The generated map with markers, lines, and convex hull polygons representing the routes.\n",
    "    \"\"\"\n",
    "    dataset = dataset.sort_values(['NEW RT', 'NEW DAY'])\n",
    "    \n",
    "    m = folium.Map(\n",
    "        location=[39.7, -76.5],\n",
    "        zoom_start=9,\n",
    "        max_zoom=20,\n",
    "        tiles='https://api.mapbox.com/styles/v1/mapbox/navigation-day-v1/tiles/256/{z}/{x}/{y}@2x?access_token=pk.eyJ1Ijoic2FtYm9zaXMiLCJhIjoiY2xyenJyM2h5MWlvMDJpcGV3NnJ3MTdkeSJ9.AGWk1gj--GW99AM0IbF3rg',\n",
    "        attr='Mapbox'\n",
    "    )\n",
    "    \n",
    "    vehicles = dataset['NEW RT'].unique()\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())[13:13+len(vehicles)]  # Adjust if more vehicles than colors\n",
    "    color_map = dict(zip(vehicles, colors))\n",
    "    \n",
    "    for vehicle in vehicles:\n",
    "        route = folium.FeatureGroup(name=f'Route {vehicle}')\n",
    "        vehicle_data = dataset[dataset['NEW RT'] == vehicle]\n",
    "        \n",
    "        # Add points for each vehicle\n",
    "        for index, row in vehicle_data.iterrows():\n",
    "            folium.CircleMarker(\n",
    "                location=[row['Latitude'], row['Longitude']],\n",
    "                color=color_map[vehicle],\n",
    "                fill=True,\n",
    "                fill_color=color_map[vehicle],\n",
    "                radius=5\n",
    "            ).add_to(route)\n",
    "        \n",
    "        locations = vehicle_data[['Latitude', 'Longitude']].values\n",
    "        if len(locations) > 2:  # ConvexHull requires at least 3 points\n",
    "            try:\n",
    "                hull = ConvexHull(locations)\n",
    "                # Drawing Convex Hull\n",
    "                hull_points = locations[hull.vertices]\n",
    "                folium.Polygon(\n",
    "                    locations=hull_points.tolist(),\n",
    "                    color=color_map[vehicle],\n",
    "                    fill=True,\n",
    "                    fill_color=color_map[vehicle],\n",
    "                    fill_opacity=0.3,\n",
    "                    weight=2\n",
    "                ).add_to(route)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not create a convex hull for vehicle {vehicle}: {e}\")\n",
    "                \n",
    "        route.add_to(m)\n",
    "    \n",
    "    Fullscreen().add_to(m)\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    m.save(\"map_with_convex_hull.html\")\n",
    "    return m\n",
    "\n",
    "def create_map_with_convex_hull_and_tooltip(dataset):\n",
    "    \"\"\"\n",
    "    Generates a map with markers, lines, convex hull polygons, and tooltips to visualize routes based on 'NEW RT'.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): A pandas DataFrame containing latitude, longitude, and other data for each point.\n",
    "\n",
    "    Returns:\n",
    "        folium.Map: The generated map with markers, lines, convex hull polygons, and tooltips representing the routes.\n",
    "    \"\"\"\n",
    "    dataset = dataset.sort_values(['NEW RT', 'NEW DAY'])\n",
    "    m = folium.Map(\n",
    "        location=[39.7, -76.5],\n",
    "        zoom_start=9,\n",
    "        max_zoom=20,\n",
    "        tiles='https://api.mapbox.com/styles/v1/mapbox/navigation-day-v1/tiles/256/{z}/{x}/{y}@2x?access_token=pk.eyJ1Ijoic2FtYm9zaXMiLCJhIjoiY2xyenJyM2h5MWlvMDJpcGV3NnJ3MTdkeSJ9.AGWk1gj--GW99AM0IbF3rg',\n",
    "        attr='Mapbox'\n",
    "    )\n",
    "    vehicles = dataset['NEW RT'].unique()\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())[13:13+len(vehicles)]  # Adjust if more vehicles than colors\n",
    "    color_map = dict(zip(vehicles, colors))\n",
    "    \n",
    "    for vehicle in vehicles:\n",
    "        route = folium.FeatureGroup(name=f'Route {vehicle}')\n",
    "        vehicle_data = dataset[dataset['NEW RT'] == vehicle]\n",
    "        \n",
    "        # Add points with tooltips for each vehicle\n",
    "        for index, row in vehicle_data.iterrows():\n",
    "            tooltip_html = f\"\"\"\n",
    "            Route: {vehicle}, Day: {row['NEW DAY']}<br>\n",
    "            Customer: {row['CUST NAME']}<br>\n",
    "            Sales: ${row['Machine']:,.2f}\n",
    "            \"\"\"\n",
    "            folium.CircleMarker(\n",
    "                location=[row['Latitude'], row['Longitude']],\n",
    "                tooltip=tooltip_html,\n",
    "                color=color_map[vehicle],\n",
    "                fill=True,\n",
    "                fill_color=color_map[vehicle],\n",
    "                radius=5\n",
    "            ).add_to(route)\n",
    "        \n",
    "        locations = vehicle_data[['Latitude', 'Longitude']].values\n",
    "        if len(locations) > 2:  # ConvexHull requires at least 3 points\n",
    "            try:\n",
    "                hull = ConvexHull(locations)\n",
    "                hull_points = locations[hull.vertices]\n",
    "                folium.Polygon(\n",
    "                    locations=hull_points.tolist(),\n",
    "                    color=color_map[vehicle],\n",
    "                    fill=True,\n",
    "                    fill_color=color_map[vehicle],\n",
    "                    fill_opacity=0.3,\n",
    "                    weight=2\n",
    "                ).add_to(route)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not create a convex hull for vehicle {vehicle}: {e}\")\n",
    "                \n",
    "        route.add_to(m)\n",
    "    \n",
    "    Fullscreen().add_to(m)\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    m.save(\"map_with_convex_hull_and_tooltip.html\")\n",
    "    return m\n",
    "from folium.plugins import Fullscreen\n",
    "\n",
    "def create_map_with_accessible_tooltips(dataset):\n",
    "    \"\"\"\n",
    "    Generates a map ensuring markers are on top of polygons for accessible tooltips.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): DataFrame containing latitude, longitude, and other data for each point.\n",
    "\n",
    "    Returns:\n",
    "        folium.Map: Generated map with markers on top of polygons.\n",
    "    \"\"\"\n",
    "    dataset = dataset.sort_values(['NEW RT', 'NEW DAY'])\n",
    "    \n",
    "    m = folium.Map(\n",
    "        location=[39.7, -76.5],\n",
    "        zoom_start=9,\n",
    "        max_zoom=20,\n",
    "        tiles='https://api.mapbox.com/styles/v1/mapbox/navigation-day-v1/tiles/256/{z}/{x}/{y}?access_token=pk.eyJ1Ijoic2FtYm9zaXMiLCJhIjoiY2xyenJyM2h5MWlvMDJpcGV3NnJ3MTdkeSJ9.AGWk1gj--GW99AM0IbF3rg',\n",
    "        attr='Mapbox'\n",
    "    )\n",
    "    \n",
    "    vehicles = dataset['NEW RT'].unique()\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())[13:13+len(vehicles)]\n",
    "    color_map = dict(zip(vehicles, colors))\n",
    "    \n",
    "    marker_groups = {}\n",
    "    \n",
    "    # Create polygons first\n",
    "    for vehicle in vehicles:\n",
    "        vehicle_data = dataset[dataset['NEW RT'] == vehicle]\n",
    "        locations = vehicle_data[['Latitude', 'Longitude']].values\n",
    "        \n",
    "        if len(locations) > 2:\n",
    "            try:\n",
    "                hull = ConvexHull(locations)\n",
    "                hull_points = locations[hull.vertices]\n",
    "                folium.Polygon(\n",
    "                    locations=hull_points.tolist(),\n",
    "                    color=color_map[vehicle],\n",
    "                    fill=True,\n",
    "                    fill_color=color_map[vehicle],\n",
    "                    fill_opacity=0.3,\n",
    "                    weight=2\n",
    "                ).add_to(m)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not create a convex hull for vehicle {vehicle}: {e}\")\n",
    "        \n",
    "        # Prepare marker groups without adding them yet\n",
    "        marker_groups[vehicle] = FeatureGroup(name=f'Route {vehicle}')\n",
    "    \n",
    "    # Add markers after polygons\n",
    "    for vehicle, group in marker_groups.items():\n",
    "        vehicle_data = dataset[dataset['NEW RT'] == vehicle]\n",
    "        for index, row in vehicle_data.iterrows():\n",
    "            tooltip_html = f\"\"\"\n",
    "            Route: {vehicle}, Day: {row['NEW DAY']}<br>\n",
    "            Customer: {row['CUST NAME']}<br>\n",
    "            Address: {row['ADDRESS']}<br>\n",
    "            Sales: ${row['Machine']:,.2f}<br>\n",
    "            Companion: ${row['Companion']:,.2f}\n",
    "            \n",
    "            \"\"\"\n",
    "            folium.CircleMarker(\n",
    "                location=[row['Latitude'], row['Longitude']],\n",
    "                tooltip=tooltip_html,\n",
    "                color=color_map[vehicle],\n",
    "                fill=True,\n",
    "                fill_color=color_map[vehicle],\n",
    "                radius=5\n",
    "            ).add_to(group)\n",
    "        group.add_to(m)\n",
    "    \n",
    "    Fullscreen().add_to(m)\n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    m.save(\"map_with_accessible_tooltips.html\")\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/376 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 376/376 [00:00<00:00, 1465.54it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path = \"./rero.xls\"\n",
    "# load reroute.xls into dataset, set the column headers to the first row of the dataset and drop the second row\n",
    "dataset = pd.read_excel(file_path)\n",
    "dataset = dataset.iloc[1:, 0:]\n",
    "dataset = dataset.reset_index(drop=True)\n",
    "# if dataset does not have a column named 'Latitude' then create it\n",
    "if 'Latitude' not in dataset.columns:\n",
    "    dataset['Latitude'] = np.nan\n",
    "# if dataset does not have a column named 'Longitude' then create it  \n",
    "if 'Longitude' not in dataset.columns:\n",
    "    dataset['Longitude'] = np.nan\n",
    "#rename BIG 5 AVG to Machine and COMP AVG to Companion\n",
    "#dataset = dataset.rename(columns={'BIG 5 AVG': 'Machine', 'COMP AVG': 'Companion'})\n",
    "prev_obj, best_obj = 999999999, 999999999\n",
    "try:\n",
    "    dataset['Machine'] =dataset['BIG 5 AVG'] \n",
    "    dataset['Companion']=dataset['COMP AVG'] \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "dataset['DAY'] = dataset['DAY'].str[:2].astype(int)\n",
    "dataset['RT'] = dataset['RT'].astype(int)\n",
    "# split the 'ADDRESS' column by comma and keep only the first part\n",
    "dataset['ADDRESS'] = dataset['ADDRESS'].str.split(',').str[0]\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "if os.path.exists('coordinates.csv'):\n",
    "    coordinates_df = pd.read_csv('coordinates.csv')\n",
    "else:\n",
    "    print(\"Creating new coordinates DataFrame...\")\n",
    "    coordinates_df = pd.DataFrame(columns=['CUST', 'Latitude', 'Longitude'])\n",
    "dataset['CUST'] = dataset['CUST'].astype(int)\n",
    "coordinates_df['CUST'] = coordinates_df['CUST'].astype(int)\n",
    "\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"my-stuff\", timeout=10)\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    #clear search_address\n",
    "    search_address = ''\n",
    "    cust = dataset.loc[i, 'CUST']\n",
    "    # First, try to get coordinates from coordinates_df\n",
    "    coord_row = coordinates_df[coordinates_df['CUST'] == cust]\n",
    "    if not coord_row.empty:\n",
    "        dataset.loc[i, 'Latitude'] = coord_row.iloc[0]['Latitude']\n",
    "        dataset.loc[i, 'Longitude'] = coord_row.iloc[0]['Longitude']\n",
    "        continue  # Skip to next iteration\n",
    "\n",
    "    short_zip = str(dataset['ZIP'][i])\n",
    "    search_address = f\"{dataset['CUST NAME'][i]}, {dataset['HOUSE NUMBER'][i]} {dataset['ADDRESS'][i]}, {dataset['CITY'][i]}, {short_zip[:5]}\"\n",
    "    location = geolocator.geocode(search_address)   # geocode method returns an object of type location\n",
    "    if location is not None:\n",
    "        dataset.loc[i, 'Latitude'] = location.latitude\n",
    "        dataset.loc[i, 'Longitude'] = location.longitude\n",
    "    else:\n",
    "        search_address = f\"{dataset['CITY'][i]} {short_zip[:5]} \"\n",
    "        location = geolocator.geocode(search_address)   # geocode method returns an object of type location\n",
    "        if location is not None:\n",
    "            dataset.loc[i, 'Latitude'] = location.latitude\n",
    "            dataset.loc[i, 'Longitude'] = location.longitude\n",
    "        else:\n",
    "            search_address = short_zip[:5]               \n",
    "            if location is not None:\n",
    "                dataset.loc[i, 'Latitude'] = location.latitude\n",
    "                dataset.loc[i, 'Longitude'] = location.longitude\n",
    "    new_row = pd.DataFrame({'CUST': [cust], 'Latitude': [location.latitude], 'Longitude': [location.longitude]})\n",
    "    coordinates_df = pd.concat([coordinates_df, new_row], ignore_index=True)\n",
    "#save dataset to csv\n",
    "coordinates_df.to_csv('coordinates.csv', index=False)\n",
    "def clean_data(dataset):\n",
    "    # Ensure 'CUST' column is of consistent data type\n",
    "    # Find the rows where the customer is the one in question and replace their coordinates\n",
    "    dataset.loc[dataset['CUST'] == 216500035, 'Longitude'] = -76.376\n",
    "    dataset.loc[dataset['CUST'] == 216500035, 'Latitude'] = 39.511\n",
    "    return dataset\n",
    "dataset = clean_data(dataset.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new distance matrix with the new latitudes and longitudes\n",
    "new_distance_matrix = pd.DataFrame(index=dataset.index, columns=dataset.index)\n",
    "new_distance_matrix.head()\n",
    "for i in range(len(dataset)):\n",
    "    for j in range(len(dataset)):\n",
    "        new_distance_matrix.iloc[i, j] = haversinedm(dataset['Latitude'][i], dataset['Longitude'][i], dataset['Latitude'][j], dataset['Longitude'][j])\n",
    "distance_matrix = new_distance_matrix\n",
    "#distance_matrix = distance_matrix.astype(int)\n",
    "distance_matrix = distance_matrix.add(.9999)\n",
    "distance_matrix = distance_matrix.astype(int)\n",
    "latlong_df = dataset[['Latitude', 'Longitude']]\n",
    "distance_matrix.to_csv('distance_matrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hygese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_model(dataset, distance_matrix, vehicle_capacity):\n",
    "    data = dict()\n",
    "    demands = dataset['Companion'].tolist()\n",
    "    data['distance_matrix'] = distance_matrix.values.tolist()\n",
    "    data['num_vehicles'] = 3\n",
    "    data['depot'] = 0\n",
    "    data['demands'] = [int(demand) for demand in demands]\n",
    "    data['vehicle_capacity'] = vehicle_capacity\n",
    "    data['service_times'] = [0] * len(data['demands'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## This is the main code that will be used to solve the problem and display the results\n",
    "#display(compute_time)\n",
    "vehicle_capacity = 10500\n",
    "compute_time = 30\n",
    "data = create_data_model(dataset, distance_matrix, vehicle_capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- FLEET SIZE SPECIFIED: SET TO 3 VEHICLES\n",
      "----- INSTANCE SUCCESSFULLY LOADED WITH 375 CLIENTS AND 3 VEHICLES\n",
      "----- BUILDING INITIAL POPULATION\n",
      "----- STARTING GENETIC ALGORITHM\n",
      "It      0      2 | T(s) 1.35 | Feas 60 1192.00 1217.96 | NO-INFEASIBLE | Div 0.51 -1.00 | Feas 1.00 1.00 | Pen 0.11 0.85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import hygese as hgs \n",
    "\n",
    "# A CVRP from https://developers.google.com/optimization/routing/cvrp\n",
    "\n",
    "\n",
    "# Solver initialization\n",
    "ap = hgs.AlgorithmParameters(timeLimit=5.2)  # seconds\n",
    "hgs_solver = hgs.Solver(parameters=ap, verbose=True)\n",
    "print(\"solver Initialized\")\n",
    "# Solve\n",
    "result = hgs_solver.solve_cvrp(data)\n",
    "print(\"Done\")\n",
    "print(result.cost)\n",
    "print(result.routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hygese import AlgorithmParameters, Solver\n",
    "def get_data():\n",
    "    data = dict()\n",
    "    data['distance_matrix'] = [\n",
    "        [0, 548, 776, 696, 582, 274, 502, 194, 308, 194, 536, 502, 388, 354, 468, 776, 662],\n",
    "        [548, 0, 684, 308, 194, 502, 730, 354, 696, 742, 1084, 594, 480, 674, 1016, 868, 1210],\n",
    "        [776, 684, 0, 992, 878, 502, 274, 810, 468, 742, 400, 1278, 1164, 1130, 788, 1552, 754],\n",
    "        [696, 308, 992, 0, 114, 650, 878, 502, 844, 890, 1232, 514, 628, 822, 1164, 560, 1358],\n",
    "        [582, 194, 878, 114, 0, 536, 764, 388, 730, 776, 1118, 400, 514, 708, 1050, 674, 1244],\n",
    "        [274, 502, 502, 650, 536, 0, 228, 308, 194, 240, 582, 776, 662, 628, 514, 1050, 708],\n",
    "        [502, 730, 274, 878, 764, 228, 0, 536, 194, 468, 354, 1004, 890, 856, 514, 1278, 480],\n",
    "        [194, 354, 810, 502, 388, 308, 536, 0, 342, 388, 730, 468, 354, 320, 662, 742, 856],\n",
    "        [308, 696, 468, 844, 730, 194, 194, 342, 0, 274, 388, 810, 696, 662, 320, 1084, 514],\n",
    "        [194, 742, 742, 890, 776, 240, 468, 388, 274, 0, 342, 536, 422, 388, 274, 810, 468],\n",
    "        [536, 1084, 400, 1232, 1118, 582, 354, 730, 388, 342, 0, 878, 764, 730, 388, 1152, 354],\n",
    "        [502, 594, 1278, 514, 400, 776, 1004, 468, 810, 536, 878, 0, 114, 308, 650, 274, 844],\n",
    "        [388, 480, 1164, 628, 514, 662, 890, 354, 696, 422, 764, 114, 0, 194, 536, 388, 730],\n",
    "        [354, 674, 1130, 822, 708, 628, 856, 320, 662, 388, 730, 308, 194, 0, 342, 422, 536],\n",
    "        [468, 1016, 788, 1164, 1050, 514, 514, 662, 320, 274, 388, 650, 536, 342, 0, 764, 194],\n",
    "        [776, 868, 1552, 560, 674, 1050, 1278, 742, 1084, 810, 1152, 274, 388, 422, 764, 0, 798],\n",
    "        [662, 1210, 754, 1358, 1244, 708, 480, 856, 514, 468, 354, 844, 730, 536, 194, 798, 0]\n",
    "    ]\n",
    "    data['num_vehicles'] = 4\n",
    "    data['depot'] = 0\n",
    "    data['demands'] = [0, 1, 1, 2, 4, 2, 4, 8, 8, 1, 2, 1, 2, 4, 4, 8, 8]\n",
    "    data['vehicle_capacity'] = 15  # different from OR-Tools: homogeneous capacity\n",
    "    print(data['distance_matrix'])\n",
    "    return data\n",
    "\n",
    "\n",
    "def test_cvrp():\n",
    "    data = get_data()\n",
    "\n",
    "    # Solver initialization\n",
    "    ap = AlgorithmParameters()\n",
    "    ap.timeLimit = 1.1\n",
    "    hgs_solver = Solver(ap, True)\n",
    "\n",
    "    # Solve\n",
    "    result = hgs_solver.solve_cvrp(data)\n",
    "    print(result.cost)\n",
    "    print(result.routes)\n",
    "    assert (result.cost == 6208)\n",
    "\n",
    "\n",
    "def test_cvrp_inputs():\n",
    "    data = get_data()\n",
    "\n",
    "    # Solver initialization\n",
    "    ap = AlgorithmParameters(timeLimit=1.1)\n",
    "    hgs_solver = Solver(parameters=ap, verbose=True)\n",
    "\n",
    "    # Solve\n",
    "    result = hgs_solver.solve_cvrp(data)\n",
    "    print(result.cost)\n",
    "    print(result.routes)\n",
    "    assert (result.cost == 6208)\n",
    "\n",
    "\n",
    "def test_cvrp_dist_mtx():\n",
    "    # Solver initialization\n",
    "    ap = AlgorithmParameters(timeLimit=3.1)\n",
    "    hgs_solver = Solver(parameters=ap, verbose=True)\n",
    "\n",
    "    data = dict()\n",
    "    n = 17\n",
    "    x = np.random.rand(n) * 1000\n",
    "    y = np.random.rand(n) * 1000\n",
    "    data['x_coordinates'] = x\n",
    "    data['y_coordinates'] = y\n",
    "\n",
    "    data['depot'] = 0\n",
    "    data['demands'] = [0, 1, 1, 2, 4, 2, 4, 8, 8, 1, 2, 1, 2, 4, 4, 8, 8]\n",
    "    data['vehicle_capacity'] = 15  # different from OR-Tools: homogeneous capacity\n",
    "\n",
    "    # Solve with calculated distances\n",
    "    dist_mtx = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            dist_mtx[i][j] = np.sqrt(\n",
    "                np.square(x[i] - x[j]) + np.square(y[i] - y[j])\n",
    "            )\n",
    "    data['distance_matrix'] = dist_mtx\n",
    "    result1 = hgs_solver.solve_cvrp(data)\n",
    "\n",
    "    # solve without distance_matrix\n",
    "    data.pop(\"distance_matrix\", None)\n",
    "    result2 = hgs_solver.solve_cvrp(data, rounding=False)\n",
    "    assert abs(result1.cost - result2.cost) < 1e-3\n",
    "\n",
    "\n",
    "def test_cvrp_duration():\n",
    "    n = 10\n",
    "    data = dict()\n",
    "    data['x_coordinates'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    data['y_coordinates'] = [5, 4, 3, 2, 1, 9, 8, 7, 6, 5]\n",
    "    data['demands'] = [0, 2, 3, 1, 2, 3, 1, 2, 3, 1]\n",
    "    data['vehicle_capacity'] = 10\n",
    "    data['duration_limit'] = 18\n",
    "    data['num_vehicles'] = 5\n",
    "\n",
    "    # Solver initialization\n",
    "    ap = AlgorithmParameters(timeLimit=1.1, seed=12, useSwapStar=True)\n",
    "    hgs_solver = Solver(parameters=ap, verbose=True)\n",
    "\n",
    "    result = hgs_solver.solve_cvrp(data, rounding=True)\n",
    "    assert result.cost == 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_data_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_data_model\u001b[49m(dataset, distance_matrix, vehicle_capacity)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#get_data()\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#test_cvrp_inputs()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#test_cvrp()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#test_cvrp_dist_mtx()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#test_cvrp_duration()\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_data_model' is not defined"
     ]
    }
   ],
   "source": [
    "#create_data_model(dataset, distance_matrix, vehicle_capacity)\n",
    "#get_data()\n",
    "#test_cvrp_inputs()\n",
    "#test_cvrp()\n",
    "#test_cvrp_dist_mtx()\n",
    "#test_cvrp_duration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- FLEET SIZE SPECIFIED: SET TO 4 VEHICLES\n",
      "----- INSTANCE SUCCESSFULLY LOADED WITH 16 CLIENTS AND 4 VEHICLES\n",
      "----- BUILDING INITIAL POPULATION\n",
      "----- STARTING GENETIC ALGORITHM\n",
      "It      0      2 | T(s) 0.01 | Feas 59 6208.00 6208.00 | Inf 1 7696.90 7696.90 | Div 0.12 -nan | Feas 0.99 1.00 | Pen 164.90 0.85\n",
      "It    500    502 | T(s) 0.05 | Feas 65 6208.00 6208.00 | Inf 4 6516.17 7117.67 | Div 0.12 0.41 | Feas 0.98 1.00 | Pen 73.17 0.38\n",
      "It   1000   1002 | T(s) 0.11 | Feas 49 6208.00 6208.00 | Inf 25 5677.94 6127.94 | Div 0.15 0.39 | Feas 0.30 1.00 | Pen 32.46 0.17\n",
      "It   1500   1502 | T(s) 0.18 | Feas 52 6208.00 6208.00 | Inf 55 5697.42 5835.48 | Div 0.13 0.15 | Feas 0.26 1.00 | Pen 33.11 0.10\n",
      "It   2000   2002 | T(s) 0.24 | Feas 40 6208.00 6208.00 | Inf 47 5717.28 5886.10 | Div 0.17 0.20 | Feas 0.25 1.00 | Pen 33.78 0.10\n",
      "It   2500   2502 | T(s) 0.31 | Feas 53 6208.00 6208.00 | Inf 57 5758.22 5893.15 | Div 0.13 0.16 | Feas 0.04 1.00 | Pen 35.14 0.10\n",
      "It   3000   3002 | T(s) 0.38 | Feas 63 6208.00 6208.00 | Inf 43 5618.01 5841.37 | Div 0.12 0.20 | Feas 0.29 1.00 | Pen 30.47 0.10\n",
      "It   3500   3502 | T(s) 0.45 | Feas 35 6208.00 6208.00 | Inf 64 5636.29 5773.76 | Div 0.18 0.13 | Feas 0.26 1.00 | Pen 31.08 0.10\n",
      "It   4000   4002 | T(s) 0.52 | Feas 51 6208.00 6208.00 | Inf 44 5528.46 5783.37 | Div 0.14 0.21 | Feas 0.27 1.00 | Pen 27.48 0.10\n",
      "It   4500   4502 | T(s) 0.59 | Feas 30 6208.00 6208.00 | Inf 49 5693.35 5890.84 | Div 0.21 0.18 | Feas 0.21 1.00 | Pen 32.98 0.10\n",
      "It   5000   5002 | T(s) 0.66 | Feas 57 6208.00 6208.00 | Inf 62 5561.77 5753.90 | Div 0.13 0.15 | Feas 0.29 1.00 | Pen 28.59 0.10\n",
      "It   5500   5502 | T(s) 0.73 | Feas 57 6208.00 6208.00 | Inf 37 5596.42 5860.24 | Div 0.13 0.27 | Feas 0.27 1.00 | Pen 29.75 0.10\n",
      "It   6000   6002 | T(s) 0.80 | Feas 26 6208.00 6208.00 | Inf 55 5818.17 5975.35 | Div 0.23 0.21 | Feas 0.13 1.00 | Pen 37.14 0.10\n",
      "It   6500   6502 | T(s) 0.86 | Feas 45 6208.00 6208.00 | Inf 63 5525.09 5708.12 | Div 0.16 0.16 | Feas 0.26 1.00 | Pen 27.37 0.10\n",
      "It   7000   7002 | T(s) 0.93 | Feas 57 6208.00 6208.00 | Inf 26 5689.31 6044.62 | Div 0.14 0.41 | Feas 0.21 1.00 | Pen 32.84 0.10\n",
      "It   7500   7502 | T(s) 1.00 | Feas 25 6208.00 6208.00 | Inf 61 5558.26 5645.02 | Div 0.24 0.12 | Feas 0.28 1.00 | Pen 28.48 0.10\n",
      "It   8000   8002 | T(s) 1.07 | Feas 28 6208.00 6208.00 | Inf 59 5729.11 5790.19 | Div 0.23 0.09 | Feas 0.22 1.00 | Pen 34.17 0.10\n",
      "It   8500   8502 | T(s) 1.15 | Feas 61 6208.00 6208.00 | Inf 28 5610.55 5951.70 | Div 0.13 0.38 | Feas 0.26 1.00 | Pen 30.22 0.10\n",
      "It   9000   9002 | T(s) 1.22 | Feas 27 6208.00 6208.00 | Inf 41 5813.62 5988.67 | Div 0.26 0.24 | Feas 0.19 1.00 | Pen 36.99 0.10\n",
      "It   9500   9502 | T(s) 1.29 | Feas 54 6208.00 6208.00 | Inf 28 5835.81 6145.47 | Div 0.14 0.38 | Feas 0.10 1.00 | Pen 37.73 0.10\n",
      "It  10000  10002 | T(s) 1.36 | Feas 30 6208.00 6208.00 | Inf 42 5666.04 5841.47 | Div 0.22 0.20 | Feas 0.23 1.00 | Pen 32.07 0.10\n",
      "It  10500  10502 | T(s) 1.44 | Feas 43 6208.00 6208.00 | Inf 41 5685.28 5884.44 | Div 0.17 0.23 | Feas 0.25 1.00 | Pen 32.71 0.10\n",
      "It  11000  11002 | T(s) 1.51 | Feas 44 6208.00 6208.00 | Inf 39 5704.90 5871.11 | Div 0.17 0.21 | Feas 0.25 1.00 | Pen 33.36 0.10\n",
      "It  11500  11502 | T(s) 1.57 | Feas 42 6208.00 6208.00 | Inf 29 5724.92 6035.60 | Div 0.17 0.37 | Feas 0.21 1.00 | Pen 34.03 0.10\n",
      "It  12000  12002 | T(s) 1.64 | Feas 39 6208.00 6208.00 | Inf 54 5589.14 5811.43 | Div 0.18 0.20 | Feas 0.26 1.00 | Pen 29.50 0.10\n",
      "It  12500  12502 | T(s) 1.70 | Feas 27 6208.00 6208.00 | Inf 60 5809.08 5953.40 | Div 0.25 0.18 | Feas 0.14 1.00 | Pen 36.84 0.10\n",
      "It  13000  13002 | T(s) 1.77 | Feas 34 6208.00 6208.00 | Inf 45 5853.72 6026.45 | Div 0.18 0.23 | Feas 0.12 1.00 | Pen 38.32 0.10\n",
      "It  13500  13502 | T(s) 1.84 | Feas 55 6208.00 6208.00 | Inf 60 5681.27 5778.69 | Div 0.15 0.11 | Feas 0.19 1.00 | Pen 32.58 0.10\n",
      "It  14000  14002 | T(s) 1.91 | Feas 26 6208.00 6297.60 | Inf 59 5700.81 5793.45 | Div 0.31 0.12 | Feas 0.24 1.00 | Pen 33.23 0.10\n",
      "It  14500  14502 | T(s) 1.98 | Feas 35 6208.00 6208.00 | Inf 63 5720.75 5801.02 | Div 0.20 0.11 | Feas 0.16 1.00 | Pen 33.89 0.10\n",
      "It  15000  15002 | T(s) 2.05 | Feas 44 6208.00 6208.00 | Inf 53 5720.75 5867.99 | Div 0.17 0.17 | Feas 0.21 1.00 | Pen 33.89 0.10\n",
      "It  15500  15502 | T(s) 2.11 | Feas 61 6208.00 6208.00 | Inf 48 5761.82 5937.01 | Div 0.13 0.19 | Feas 0.34 1.00 | Pen 35.26 0.10\n",
      "It  16000  16002 | T(s) 2.19 | Feas 28 6208.00 6208.00 | Inf 36 5804.56 6001.98 | Div 0.25 0.27 | Feas 0.25 1.00 | Pen 36.69 0.10\n",
      "It  16500  16502 | T(s) 2.26 | Feas 28 6208.00 6208.00 | Inf 65 5849.02 5982.71 | Div 0.25 0.17 | Feas 0.08 1.00 | Pen 38.17 0.10\n",
      "It  17000  17002 | T(s) 2.33 | Feas 36 6208.00 6208.00 | Inf 57 5696.73 5790.49 | Div 0.19 0.13 | Feas 0.00 1.00 | Pen 33.09 0.10\n",
      "It  17500  17502 | T(s) 2.40 | Feas 25 6208.00 6342.40 | Inf 56 5716.59 5838.55 | Div 0.33 0.14 | Feas 0.22 1.00 | Pen 33.75 0.10\n",
      "It  18000  18002 | T(s) 2.48 | Feas 33 6208.00 6208.00 | Inf 26 5757.50 6077.37 | Div 0.21 0.40 | Feas 0.25 1.00 | Pen 35.12 0.10\n",
      "It  18500  18502 | T(s) 2.55 | Feas 54 6208.00 6208.00 | Inf 60 5778.57 5827.38 | Div 0.15 0.08 | Feas 0.00 1.00 | Pen 35.82 0.10\n",
      "It  19000  19002 | T(s) 2.62 | Feas 33 6208.00 6208.00 | Inf 44 5800.06 5995.07 | Div 0.21 0.24 | Feas 0.18 1.00 | Pen 36.54 0.10\n",
      "It  19500  19502 | T(s) 2.68 | Feas 39 6208.00 6208.00 | Inf 60 5844.34 5950.72 | Div 0.19 0.15 | Feas 0.11 1.00 | Pen 38.01 0.10\n",
      "----- RESET: CREATING A NEW POPULATION -----\n",
      "----- BUILDING INITIAL POPULATION\n",
      "It  20000      3 | T(s) 2.76 | Feas 49 6208.00 6208.00 | Inf 61 5692.67 5713.59 | Div 0.13 0.04 | Feas 0.00 1.00 | Pen 32.96 0.10\n",
      "It  20500    503 | T(s) 2.83 | Feas 40 6208.00 6208.00 | Inf 31 5732.62 6030.72 | Div 0.17 0.34 | Feas 0.00 1.00 | Pen 34.29 0.10\n",
      "It  21000   1003 | T(s) 2.90 | Feas 63 6208.00 6208.00 | Inf 29 5753.19 6088.50 | Div 0.12 0.37 | Feas 0.00 1.00 | Pen 34.97 0.10\n",
      "It  21500   1503 | T(s) 2.96 | Feas 65 6208.00 6208.00 | Inf 58 5774.17 5930.28 | Div 0.12 0.16 | Feas 0.20 1.00 | Pen 35.67 0.10\n",
      "It  22000   2003 | T(s) 3.03 | Feas 25 6208.00 6252.80 | Inf 43 5631.84 5850.44 | Div 0.27 0.21 | Feas 0.32 1.00 | Pen 30.93 0.10\n",
      "It  22500   2503 | T(s) 3.10 | Feas 41 6208.00 6208.00 | Inf 32 5669.32 5947.30 | Div 0.16 0.32 | Feas 0.26 1.00 | Pen 32.18 0.10\n",
      "It  23000   3003 | T(s) 3.16 | Feas 46 6208.00 6208.00 | Inf 32 5708.32 5989.18 | Div 0.15 0.32 | Feas 0.27 1.00 | Pen 33.48 0.10\n",
      "----- GENETIC ALGORITHM FINISHED AFTER 23272 ITERATIONS. TIME SPENT: 3.2001\n",
      "6208.0\n",
      "[[14, 16, 10, 9], [5, 2, 6, 8], [1, 4, 3, 7], [13, 15, 11, 12]]\n"
     ]
    }
   ],
   "source": [
    "# A CVRP from https://developers.google.com/optimization/routing/cvrp\n",
    "import numpy as np \n",
    "import hygese as hgs \n",
    "\n",
    "data = dict()\n",
    "data['distance_matrix'] = [\n",
    "    [0, 548, 776, 696, 582, 274, 502, 194, 308, 194, 536, 502, 388, 354, 468, 776, 662],\n",
    "    [548, 0, 684, 308, 194, 502, 730, 354, 696, 742, 1084, 594, 480, 674, 1016, 868, 1210],\n",
    "    [776, 684, 0, 992, 878, 502, 274, 810, 468, 742, 400, 1278, 1164, 1130, 788, 1552, 754],\n",
    "    [696, 308, 992, 0, 114, 650, 878, 502, 844, 890, 1232, 514, 628, 822, 1164, 560, 1358],\n",
    "    [582, 194, 878, 114, 0, 536, 764, 388, 730, 776, 1118, 400, 514, 708, 1050, 674, 1244],\n",
    "    [274, 502, 502, 650, 536, 0, 228, 308, 194, 240, 582, 776, 662, 628, 514, 1050, 708],\n",
    "    [502, 730, 274, 878, 764, 228, 0, 536, 194, 468, 354, 1004, 890, 856, 514, 1278, 480],\n",
    "    [194, 354, 810, 502, 388, 308, 536, 0, 342, 388, 730, 468, 354, 320, 662, 742, 856],\n",
    "    [308, 696, 468, 844, 730, 194, 194, 342, 0, 274, 388, 810, 696, 662, 320, 1084, 514],\n",
    "    [194, 742, 742, 890, 776, 240, 468, 388, 274, 0, 342, 536, 422, 388, 274, 810, 468],\n",
    "    [536, 1084, 400, 1232, 1118, 582, 354, 730, 388, 342, 0, 878, 764, 730, 388, 1152, 354],\n",
    "    [502, 594, 1278, 514, 400, 776, 1004, 468, 810, 536, 878, 0, 114, 308, 650, 274, 844],\n",
    "    [388, 480, 1164, 628, 514, 662, 890, 354, 696, 422, 764, 114, 0, 194, 536, 388, 730],\n",
    "    [354, 674, 1130, 822, 708, 628, 856, 320, 662, 388, 730, 308, 194, 0, 342, 422, 536],\n",
    "    [468, 1016, 788, 1164, 1050, 514, 514, 662, 320, 274, 388, 650, 536, 342, 0, 764, 194],\n",
    "    [776, 868, 1552, 560, 674, 1050, 1278, 742, 1084, 810, 1152, 274, 388, 422, 764, 0, 798],\n",
    "    [662, 1210, 754, 1358, 1244, 708, 480, 856, 514, 468, 354, 844, 730, 536, 194, 798, 0]\n",
    "]\n",
    "data['num_vehicles'] = 4\n",
    "data['depot'] = 0\n",
    "data['demands'] = [0, 1, 1, 2, 4, 2, 4, 8, 8, 1, 2, 1, 2, 4, 4, 8, 8]\n",
    "data['vehicle_capacity'] = 15  # different from OR-Tools: homogeneous capacity\n",
    "data['service_times'] = np.zeros(len(data['demands']))\n",
    "\n",
    "# Solver initialization\n",
    "ap = hgs.AlgorithmParameters(timeLimit=3.2)  # seconds\n",
    "hgs_solver = hgs.Solver(parameters=ap, verbose=True)\n",
    "\n",
    "# Solve\n",
    "result = hgs_solver.solve_cvrp(data)\n",
    "print(result.cost)\n",
    "print(result.routes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
